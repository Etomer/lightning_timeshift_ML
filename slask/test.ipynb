{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (5.2.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# --------- Notebook code to have the same import behavior as .py files --------------\n",
    "#%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "if 'notebook_path' not in vars():\n",
    "    notebook_path = os.getcwd()\n",
    "os.chdir(os.path.join(notebook_path,\"..\"))\n",
    "sys.path.append(os.getcwd())\n",
    "# -----------------------------------------------------------------------------------\n",
    "#from src.data_modules.impulse_response import ImpulseResponseDataModule\n",
    "\n",
    "import h5py\n",
    "import lightning as L\n",
    "from src.data_modules import MovingImpulseResponseDataModule\n",
    "from src.cnn_model import cnn_model\n",
    "#ImpulseResponseDataModule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch\n",
    "sys.path.append(os.getcwd())\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from src.data_modules import MovingImpulseResponseDataModule\n",
    "from src.cnn_model_v2 import cnn_model_v2\n",
    "import src.data_augmentations as data_augmentations\n",
    "from torchvision import transforms\n",
    "#model = cnn_model_v2(scale_cnn_width=2, n_blocks=2, block_width=2000) # from scratch\n",
    "\n",
    "model = cnn_model_v2.load_from_checkpoint(\"lightning_logs/xovhkfm1/checkpoints/epoch=16149-step=48450.ckpt\", scale_model_width=2, n_blocks=2, block_width=2000) # from check point\n",
    "\n",
    "#data_path = \"./data/datasets/moving_dataset_medium.hdf5\"\n",
    "data_path = \"data/datasets/moving_dataset_directivity_medium_extra_val.hdf5\"\n",
    "data_val_path = \"data/datasets/moving_dataset_directivity_medium_extra_val2.hdf5\"\n",
    "sound_dir = \"./data/reference_data/reference_sounds/\"\n",
    "transform = transforms.Compose([data_augmentations.doppler_aug(max_rel_v=1), data_augmentations.noise_aug(noise_ratio=0.001)])\n",
    "data_module = MovingImpulseResponseDataModule(data_path,sound_dir,batch_size=50, transform=transform, n_mics_per_batch=5, data_val_path=data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 45.59it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     val/loss_epoch         0.07344315201044083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val/loss_epoch': 0.07344315201044083}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb_logger = WandbLogger(log_model=\"all\")\n",
    "\n",
    "#checkpoint_callback = ModelCheckpoint(every_n_epochs=50)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=30000,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=1,#[1],\n",
    "    log_every_n_steps=50,\n",
    "    logger = L.pytorch.loggers.CSVLogger(\"logs\", name=\"my_exp_name\"),\n",
    "    #terminate_on_nan=True,\n",
    " #   callbacks=[checkpoint_callback],\n",
    "    deterministic=True,\n",
    ")\n",
    "trainer.validate(model, datamodule = data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/er6236te/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 15.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     val/loss_epoch          6.158205986022949\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val/loss_epoch': 6.158205986022949}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.gcc_phat_model import gcc_phat_model\n",
    "import os, sys, torch\n",
    "sys.path.append(os.getcwd())\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from src.data_modules import MovingImpulseResponseDataModule\n",
    "from src.cnn_model_v2 import cnn_model_v2\n",
    "import src.data_augmentations as data_augmentations\n",
    "from torchvision import transforms\n",
    "#model = cnn_model_v2(scale_cnn_width=2, n_blocks=2, block_width=2000) # from scratch\n",
    "\n",
    "#model = cnn_model_v2.load_from_checkpoint(\"lightning_logs/xovhkfm1/checkpoints/epoch=16149-step=48450.ckpt\", scale_model_width=2, n_blocks=2, block_width=2000) # from check point\n",
    "\n",
    "#data_path = \"./data/datasets/moving_dataset_medium.hdf5\"\n",
    "data_path = \"data/datasets/moving_dataset_directivity_medium_extra_val.hdf5\"\n",
    "data_val_path = \"data/datasets/moving_dataset_directivity_easy_tiny_val.hdf5\"\n",
    "sound_dir = \"./data/reference_data/reference_sounds/\"\n",
    "transform = transforms.Compose([data_augmentations.doppler_aug(max_rel_v=1), data_augmentations.noise_aug(noise_ratio=0.001)])\n",
    "data_module = MovingImpulseResponseDataModule(data_path,sound_dir,batch_size=50, transform=transform, n_mics_per_batch=5, data_val_path=data_val_path)\n",
    "\n",
    "\n",
    "\n",
    "model = gcc_phat_model(data_module.n_shift_bins,data_module.max_shift, data_module.sample_length, temperature_scaling=10)\n",
    "\n",
    "trainer = L.Trainer(accelerator=\"cpu\")\n",
    "trainer.validate(model, data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f348ca61a80>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD7CAYAAACBiVhwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABGEUlEQVR4nO2dd3gc1bn/v+/uqlnFsi25F8m4gA3GGGFMD6HZhmASwr2G3EAIxD8CpNzchGsCIQFCyA2phOKQ3BQSCBdCiQOmg+kGN9xtLBdsWa6yLclq297fHzNn9szs7O5IWmnX2vfzPH6snTlnZs7uzPmet5wzxMwQBEEQBB1fpi9AEARByD5EHARBEIQ4RBwEQRCEOEQcBEEQhDhEHARBEIQ4RBwEQRCEODyJAxHNJKJNRFRLRPNd9hMR3W/uX01E0zpR97tExERUYX6uIqI2IvrY/LegOw0UBEEQOk8gVQEi8gN4EMAFAOoALCWihcy8Xis2C8B489+pAB4GcGqqukQ0yty3w3HaLcw8tTsNEwRBELpOSnEAMB1ALTNvBQAiegLAHAC6OMwB8CgbM+qWEFE5EQ0DUJWi7q8A3ALgn91pREVFBVdVVXXnEIIgCDnH8uXLDzBzpds+L+IwAsBO7XMdDOsgVZkRyeoS0aUAdjHzKiJynrOaiFYCaAJwOzO/k+wCq6qqsGzZMg9NEQRBEBRE9GmifV7EIa7nBuBccyNRGdftRNQPwG0ALnTZvxvAaGZuIKKTATxHRJOZucl2QqJ5AOYBwOjRo1M0QRAEQegMXgLSdQBGaZ9HAqj3WCbR9mMAVANYRUTbze0riGgoM3cwcwMAMPNyAFsATHBeFDM/wsw1zFxTWelqFQmCIAhdxIs4LAUwnoiqiSgfwFwACx1lFgK42sxamgGgkZl3J6rLzGuYeTAzVzFzFQwRmcbMe4io0gxkg4jGwghyb01HYwVBEARvpHQrMXOYiG4G8DIAP4A/MvM6IrrB3L8AwCIAswHUAmgFcG2yuilOeTaAu4goDCAC4AZmPtil1gmCIAhdgvrCkt01NTUsAWlBEITOQUTLmbnGbZ/MkBYEQRDiEHEQBEEQ4hBxEISjgJfW7sGBIx2ZvgwhhxBxEIQspz0UwdcfW45nVtRl+lKEHELEQRCynCgzmIFQ5OhPHhGOHkQcBCHLiURFFITeR8RBELIcpQ19Ie1cOHoQcRCELEeJghgQQm8i4iAIWY5yK4nhIPQmIg6CkOVYbqW4xZAFoecQcRCELEe5lcRyEHoTEQdByHJiloMg9B4iDoKQ5UTYSlfK7IUIOYWIgyBkOVEVkM7wdQi5hYiDIGQ5YjgImUDEQRCynKgKSIvtIPQiIg6CkOVEJFtJyAAiDoKQ5ViprBm+DiG3EHEQhCwnKjEHIQOIOAhCliMxByETeBIHIppJRJuIqJaI5rvsJyK639y/moimdaLud4mIiahC23arWX4TEV3U1cYJQl8gIrPghAyQUhyIyA/gQQCzAEwCcCURTXIUmwVgvPlvHoCHvdQlolEALgCwQ9s2CcBcAJMBzATwkHkcQchJWLRByABeLIfpAGqZeSszBwE8AWCOo8wcAI+ywRIA5UQ0zEPdXwG4Bfb7fg6AJ5i5g5m3Aag1jyMIOYlyK0VlzW6hF/EiDiMA7NQ+15nbvJRJWJeILgWwi5lXdeF8IKJ5RLSMiJbt37/fQzME4ehEvEpCJvAiDuSyzXmfJirjup2I+gG4DcAdXTwfmPkRZq5h5prKykqXKoLQN5D3OQiZIOChTB2AUdrnkQDqPZbJT7D9GADVAFYRkdq+goimezyfIOQMLNlKQgbwYjksBTCeiKqJKB9GsHiho8xCAFebWUszADQy8+5EdZl5DTMPZuYqZq6CIQjTmHmPeay5RFRARNUwgtwfpaOxgnA0IvMchEyQ0nJg5jAR3QzgZQB+AH9k5nVEdIO5fwGARQBmwwgetwK4NlndFOdbR0RPAlgPIAzgJmaOdLWBgnC0E5FAtJABvLiVwMyLYAiAvm2B9jcDuMlrXZcyVY7P9wC4x8u1CUJfJ/YmOBEJofeQGdKCkOVItpKQCUQcBCHLicqqrEIGEHEQhCwnItlKQgYQcRCELIfFchAygIiDIGQ50ajxv2iD0JuIOAhCliMxByETiDgIQpYTtVRB1EHoPUQcBCHLkRnSQiYQcRCELMdaslvUQehFRBwEIcsRy0HIBCIOgpDlqJf8iDYIvYmIgyBkOZKtJGQCEQdByHJiayuJOgi9h4iDIGQ5ViBatEHoRUQcBCHLkZiDkAlEHAQhy4llK4k8CL2HiIMgZDlWQDrD1yHkFiIOgpDlyKqsQiYQcRCELCciMQchA4g4CEKWIzEHIRN4EgcimklEm4iolojmu+wnIrrf3L+aiKalqktEd5tlPyaiV4houLm9iojazO0fE9GCdDRUEI5WJOYgZIKU4kBEfgAPApgFYBKAK4lokqPYLADjzX/zADzsoe59zDyFmacCeB7AHdrxtjDzVPPfDV1tnCD0BWSeg5AJvFgO0wHUMvNWZg4CeALAHEeZOQAeZYMlAMqJaFiyuszcpNUvhtz6guCKzJAWMoEXcRgBYKf2uc7c5qVM0rpEdA8R7QTwJdgth2oiWklEbxHRWW4XRUTziGgZES3bv3+/h2YIwtGJtWR3NMMXIuQUXsSBXLY5hzCJyiSty8y3MfMoAI8BuNncvBvAaGY+CcB3ADxORGVxB2F+hJlrmLmmsrLSQzME4eiExXIQMoAXcagDMEr7PBJAvccyXuoCwOMALgcAZu5g5gbz7+UAtgCY4OE6BaFPYqWyijYIvYgXcVgKYDwRVRNRPoC5ABY6yiwEcLWZtTQDQCMz705Wl4jGa/UvBbDR3F5pBrJBRGNhBLm3drmFgnCUI9lKQiYIpCrAzGEiuhnAywD8AP7IzOuI6AZz/wIAiwDMBlALoBXAtcnqmof+KRFNBBAF8CkAlZV0NoC7iCgMIALgBmY+mJbWCsJRiLwJTsgEKcUBAJh5EQwB0Lct0P5mADd5rWtuvzxB+acBPO3lugQhF4hNfhN1EHoPmSEtCFmOxByETCDiIAhZTlTmwAkZQMRBELKc2KqsIg9C7yHiIAhZjmQrCZlAxEEQspyIOTNaDAehNxFxEIQsRywHIROIOAhCliMxByETiDgIQpYTFU0QMoCIgyBkORF5h7SQAUQcBCHLUe6kqKiD0IuIOAhClhOVbCUhA4g4CEKWE8tWEnUQeg8RB0HIciTmIGQCEQdByHJY1lYSMoCIgyBkOVFRByEDiDgIQpZjLdkt6iD0IiIOgpDlWIaDaIPQi4g4CEKWI2srCZlAxEEQspyorK0kZAARB0HIcqwluzN7GUKO4UkciGgmEW0ioloimu+yn4jofnP/aiKalqouEd1tlv2YiF4houHavlvN8puI6KLuNlIQjmZY5jkIGSClOBCRH8CDAGYBmATgSiKa5Cg2C8B48988AA97qHsfM09h5qkAngdwh1lnEoC5ACYDmAngIfM4gpCTSMxByAReLIfpAGqZeSszBwE8AWCOo8wcAI+ywRIA5UQ0LFldZm7S6hcjdu/PAfAEM3cw8zYAteZxBCEnsZbsFtNB6EW8iMMIADu1z3XmNi9lktYlonuIaCeAL8G0HDyeD0Q0j4iWEdGy/fv3e2iGIBydiOUgZAIv4kAu25z3aaIySesy823MPArAYwBu7sT5wMyPMHMNM9dUVla6Xrgg9AWismS3kAG8iEMdgFHa55EA6j2W8VIXAB4HcHknzicIOYMs2S1kAi/isBTAeCKqJqJ8GMHihY4yCwFcbWYtzQDQyMy7k9UlovFa/UsBbNSONZeICoioGkaQ+6Mutk8Qjnqikq0kZIBAqgLMHCaimwG8DMAP4I/MvI6IbjD3LwCwCMBsGMHjVgDXJqtrHvqnRDQRQBTApwDU8dYR0ZMA1gMIA7iJmSPparAgHG1IzEHIBCnFAQCYeREMAdC3LdD+ZgA3ea1rbr/cpbjadw+Ae7xcmyD0dVS2ksyQFnoTmSEtCFmOBKKFTCDiIAhZTsxyyOx1CLmFiIMgZDlReZ+DkAFEHAQhy5FsJSETiDgIQjdgZvzspY3YvLe5x85huZV67AyCEI+IgyB0g4MtQTy0eAuu+sOHPXYOy61kmg5PLt2JrfuP9Nj5BAEQcRCEbqFG85Foz43r9XkOzIxbnl6NOQ+812PnEwRAxEEQsh4rlZWBUMT4u7kjnMErEnIBEQdB6Aaq43ZbLTJdaNqAoHotnCD0MCIOgtANetKdZJ1De4d0MGyIg68n1UgQIOIgCN0ibLp5qAc769iS3bDEIeCTR1foWeQOE4Ru0BuWg7VkNzTLQZ5coYeRW0wQukHYEoeeMx1YmwQXjBgLFIvlIPQ0cocJQjfo3ZgD0GFaDn4JOgg9jIiDIHSDcLTns4d0/QmKOAi9hIiDIHQDZTn0ZECaXbKVRByEnkbEQcgZolHGrsNtKctt2X8E72854OmY4d4ISLvMc/D3pBoJAkQchBziV699gjN++gbqDrUmLXfeL97CVb/3tlaSZTl0++pSn4NZ3EpC7yHiIOQMr23YBwA43BpK2zHVPIeeJLa2UsytFPCLOAg9i4iDkDN0hI000IJA+m773ok5xP4Xt5LQW3h6SohoJhFtIqJaIprvsp+I6H5z/2oimpaqLhHdR0QbzfLPElG5ub2KiNqI6GPz34I0tFMQ0BEyOtZ0jvV7J1sptiqrpLIKvUVKcSAiP4AHAcwCMAnAlUQ0yVFsFoDx5r95AB72UPdVAMcz8xQAnwC4VTveFmaeav67oauNEwQd1bGG0rh4Xa/Mc5CYg5ABvFgO0wHUMvNWZg4CeALAHEeZOQAeZYMlAMqJaFiyusz8CjOrdYeXABiZhvYIQkKUWymdHXrYCkj35Axp6y8RB6HX8CIOIwDs1D7Xmdu8lPFSFwC+CuBF7XM1Ea0koreI6Cy3iyKieUS0jIiW7d+/30MzhFwnZjmkTxx6ZW0l2/IZauE9EQehZ/EiDm53ofOJSFQmZV0iug1AGMBj5qbdAEYz80kAvgPgcSIqizsI8yPMXMPMNZWVlSmaIAgxl0w4jW6l3pnnEIs5xBbeE3EQehYv4lAHYJT2eSSAeo9lktYlomsAXALgS2xOA2XmDmZuMP9eDmALgAleGiMIXkjnaD/SwwFpZrYmwUW1GdLZwP8t3YHXN+zN9GUIPYQXcVgKYDwRVRNRPoC5ABY6yiwEcLWZtTQDQCMz705Wl4hmAvhvAJcyszUriYgqzUA2iGgsjCD31m61UhA0QmkVh7QdyhVm+9/KrRTtBYslFf/99Bpc95dlmb4MoYdIKQ5m0PhmAC8D2ADgSWZeR0Q3EJHKJFoEowOvBfB7ADcmq2vWeQBAKYBXHSmrZwNYTUSrAPwDwA3MfLD7TRUEg3S6lZTl0FPTDqKaOuhrK6XDnRWJMr7595VYu6ux28fKVpZtP4jjfvASDrYEM30pRx0BL4WYeREMAdC3LdD+ZgA3ea1rbh+XoPzTAJ72cl2C0BXSGZDu6ZhDRBcHpDfj6mBLEAtX1WPS8DIcP6J/t4+XjSx4awvaQhEs234QF04emunLOaqQGdJC2ohGGd/4+0os/zT7DD3WOtn0xhx6dm0l3a0EBlqD6RMHNYHvSHs4RcmjFzJNusw74Y4+RByEtHGoNYh/rarH9Vnoh24xO1UAuPnvK1DvYXXWRPz29c345SubAHhbW+mZFXVoau/aek5Rh+XQ0mGKA6dBHMxrb+7itR0NKNHmNHxfuYaIg5A2lLsmGydoNbXFOkBm4Pbn1qas49ahNLaF8ItXP8H9b9QC0NdWcm/zxj1N+M6Tq3DLU6u7ctm2F/0wM1qDxii/KwHp7Qda8OX//RAtHcYxlEusuaPvWg4+83fJgvj9UYeIg5A22kLGqNaXJYvCNRzpsP5ubLOPjpvaUo+W3Vw3H22zu8xSxRzU6HzHweTLhKe6Bh+ZloNpAXUl1nHfy5vwzuYDeH3jPvPaDLdScx92K6lXbUfFcug0Ig5C2mgLZo84vLZ+L07+8Wt4v9Z4aY9TDJxi4YZb/6sCwopU8xzUV9HV9ZyU9eL3EZiB1o6uWw4lBUb+iYoxKEuvKzGHo8VNQ2I5dBkRByFtKMshG9xKS82g+Md1hwHEi4E3cYjvUZzWRKoRfLCbi/2pw/uIwGArIJ3qvHub2nG41Z6+WWyKQ8ytZFoOHZ2POejfQzoXMkw3XYk5bN7bnBXzSDKNiIOQNizLIQvuKmW9qD6hyTE69hIgdhMHZxqs6iQTuS26u56TOm7AtBxaVMwhRWd36k9ex2n3vmHbVlLgBwAc6bBbDl1xK+nipAYF2Yi6D5R7rzUYTvrbr69vwgW/ehsPv7WlV66vqzy8eAtufWZNj54jCx5joa9gWQ5pdCsdbg3ijn+uRXsnOyDniNFpKbSHUo92o2xMotJHkc4JdKqTTJRa2t1lwtW5fT4CA2jt8J7K6uy0C/Ls4qCO0RW3UlBrT3uw++JQu68Zh3pgopqyYtX1nnPfYkz50SsJy6tXyK749FDaryWd/M9LG/H3j3b06DlEHIS0YQWkE7iV7l20odOjnYff2oJHP/i00w+C0ifLcvDgRnKyeW8zvrjgA7y9Obbqr3PpjUgKcVCitq+5A396b1unr0Ed1u8jhCJRq5PrSkBajZ4tt1I3AtIhbY2ndFgO5//ybcy+/51uH8eJuhOVe29/c0fiwojNh8iCsFnGEXGA0Ql864mV1kPTVwhHovjeU6uweW+ztW3nwVZUzX+hR5ZMaDNdHn4iNLWHsO1Ai23/797e2ulOvsgc7TYcST6qZGbb6NyZwtjYFrICsordjW3Ysv9IwmOqd03rHYpuOTCz1eEmmnfQoXWid/5rfactIOU+8hNZQuf3UZd84ur7UVaUErpgJBoXaE+FLk4qDrKjobVbgerdje1drpsIFZD2umBh7PJFHUQcAPxk0Qb88+N6/HXJp5m+lLSyvaEFTy2vw7y/Lre2qVU0n1q2M1G1LqNnK53y49dw7s8Xd/uYA4vzAQAHW5OLw23PrcX4215E1fwXUH+4LeZWMseCB1uCGFCcZ6vzX0+uwnm/eAvLtrvP6FYduT6y1ie9hSJsZSsdbg3hzU374o7R4RCDdfWdE+Wolq2kKC0MeLYc9M5aWR0NpvtGF7rm9jAWrqrHvib3Dnrp9oN465OYBRV0WA7r6htx9n1v4k/vbfd0XYloD0VQuy+xYHcW9bU1d4SxRxOfxOtrqXkrabuEHiWd64Q5yXlxiEQZy0z/4tuf9O5Lg15Zt6fHrJXafUew85AxC3hPJ0Zkyz89iJ1dzMlvM/34+5rbbSPm7pDvN27RxtbkbqHHP4xZJB9sacDGPYa1pPrGPY3tGNa/yFbnQ3POQiIrSrXhiPYb6Z1yMBK1fb72T0sTHkPRFrR/bjjSkbRtKlM24BAHZ0D6hdW7Mes374CZbS4ufWa46tAPmJaQHiRvOBLEN/++EpcveN/1Oq5Y8AGu+eNH1ueQI+awy7zX3jNThzuDLmA3P74S5//yrU5bMqm4//XNmHHv69ZnZ4KCQn0n3dGG3kzzVTPme4KcF4dP9jZbI8PeXCt/R0Mr5v11Ob73j1XWtjkPvIvvPrUqSS3vnP/Lt6zOSvcJp7ptL3/4A5xz35tdOqdyKx1K0ZF74UhHGKff+zre29JgHtN7sPK/n16NV9YbFpJq7+6mNgzrX+ha/qHFW7Bka0Pc9pjlEGuPPlILhaNxsQan2MeJg8OSOPnHr+HEuxIHSJUI6HGc0oK8uPN+84mV2LC7CcFI1Oa60oO8ynLYZ4pDWJujoSYM7jzobVkRZ7ZSfsBnO0dn0Nvy1ieG9dXVZ/Gmx1agav4Lrtep09gWwo+fX48vPmwXQ/XdddVyeHPjPlTfugjbHS7VnuJIsOdc4TkvDit3HAYAjK0o7tKN3VWCEeMmXLUzNmpdVdeIfyyv65HzdSZbJpXHYl9TO/a6uB/cApNdzRdfX9+E+sZ2/GuV8W6o97c0YLGL20ahx8DDjhz8aJSxt7EDQx3ioDqlfc0dmPvIkrhjurmVQkksBwBYY1ohja0hMHPcCLi1kw9zIrdSlO0jVCsrJ+wQB01Ug5ol1NIRtnXKBzqZKdSmWSTtoajl2++KxahbMOr7/OfH9V0agb+wZrfj2O7X09gWwh/e3WZ5DRTt5vV39Z3g97+xGQCSxrK6i/699OSiiTkvDuvqG1FWGMAxg0tSjla2HWjBB1viR5iJWLXzsM0loaOCeF1ZkK12X3NSX6PbQ5UqSwNw918yM37w3Fqs2BF7iKb/5HWc+pPXbeU+bWjB79+Jz8ZRnYXzmkKRKM77xeKEAeqCQPytqVxF7uX9rts7QlE0tAQRjEQx3OFWcuJsv7p2e8whVqapLRQn5nMfWYI/vLMVJ971Cp5aXocO09X20reNV6EnCkhv2tMcdy+s3dVopdzq4lBWZMRO9M7dr3XO7dp9rHdSeke5r7nD1ikfPJL4/nAKXHsogjkPvmfbr9qlnqHHP9yBz3qMOQVtQX7j/9ufW5uWgVKihRETTYJUabldtRzW1BmDg3Qt5f7dp1bh1699YtumD8IS9S/pIOfF4cARY0SZH/CltBzO/fliXPl7Y4Spv3jFjZaOMOY8+B6+8fiKBPvjR6UKNx/4mrpG/Pb1zWhqD+H8X76Nyxd8YNv/vadWWea02+htT4JAo+2aXPLV9x/pwF+XfIp5jy6P23eoJYgfLVyH9lAEq+sS+e3NTsPx3R5qCWLL/hbc+swaV+sizx9/a7YlyacvzHO/lTvCESvm4rQcnGx2BEJVx9zcEcbtz63B1/+23PbQL97kHqP68QsbAABvbdqPjnAU+QEfhpQWJm3DRb9+G1c8HPtN9za145LfvotbnzVSf/W5I6WFRtaVfi1KPDoclsMTH8USD/T7dW9Tu03oGjTLQbnR1tc34ZZ/rMLE21+yXavTddYeitrEIRplfP/ZNdh6oMWTeyjR6H5/EsFKhRLORMfWZ4/r959qx4tr96Bq/gu4/i/xcaREhDRLck9je7djD63BMP6xvA6/fm2zbbse9H96RV2Pvawp58XhUEsIA4vzUeD3dcrP+dDiLZhw+4v4ZK/7aFZ1+mt2Nbnud7oX9Bvpkt++G1f+cw+8i1+8+gn2mh3dqp2Hbcd4ShtluY1OvQSl3YLjygddVhT/XqglWxvw5/e3Y82uxriHMOCzuxlatcBZOBK1jXgOu4ziog6XSWGeD795fXPCjLLCPHfLoT0Uxe5Gow2JYg6KhiNBW0ehhK25PYS/LdmBF9fusfmSd5nLfo8c4G6RBPyEjnAEBQEfivKN62tLMvlu095mtIciqD/cZn0/q3YeBuCwHAoNy0H/jtTujlBsFD9qYBFW1R222hQMR60A/96mdpuLTBcHFZOYff87eHKZffTOzHFC366dMxiJWgMoILUb7U/vbcMjb7u/BTjVGl2LN+3DdX9e6toJq9F1olfC6vNe1KzzhiMd+MWr9lH6axsSuzKd6PfGDxeuQ/Wti3DXv9Z7ru/k3c3uwf37Xt5k/f34hzvw8OKemc2d8+LQ0NKBgcX5huXgURxCkSje32L8cPrITEe5CNzcI0DMrQQYnaVzeQX9htdHOZ82xDKJ3EzjaJRts39Vh6hyyPXnaPPeZmzV3A5uJqqaMVpRUhC3Tz2Ah1qClhjOPsF429aogf0AwHKrtGidRDAStWVZuImSPirO9/vQL98Qpx8kWGo78QzliGU1pbIcmttDtvkK6nvcqwmrCnQDMXEYUuZ+XL+P0B6KoiDgt+6DVBPG5j+9Gqf/9I249ugdZZlpOURcLAcjIG1c98QhZWgPRa3OPhiJYnCZ8Ts2tYXsloM2Sk82p6QjHLV+U32bOmfDkQ4rCwyw3+eAkVW1p7EdwXAUTe0h/GtVPZ5MkFbtt5a+iLpaXNf/ZRle37jP9RWgSpQSuV/rtd9U3fc/XLjOtaxXPtkbH2f4o2Pi43Mrd1kisnFPE879+eKErzB93RSmEeWxwYebEF46dXiXrzkZOS8Oh1pDGNAvH3l+n+egbXN72LpZD7UGE677DwAFCdwd+ohq8ab9cZ2G3lHv0l5Ms70hNjppaovvVNs1/y8AVFcUAwDufn49Go502No4/5k11nsNVu44hDc2xkZJ//uucVOrtNZB5nyDqCNLBTBy/JUrQn0VajS9r7kdVz6yxAr8A4Zr5ekVsRFpi8voUn+o8/xkTYZLREtH2BoV6zy/ejfW7WpCnp9QURwvcDpN7SFbh9tuWg71Cayu+sNtKCsMJBxU5Pl8luVAZLRh897mpPfZcjO2s8bhpgv4dbeSS8xBWWqhqDW34tihpQBi90wwHLV+x6b2sM0frwtCQxJ3TlswYn0vCt1ycGaq6fd5U3sINz2+AvP+ugzX/WUppvzoFbQGI9ZkQydKD6/6w4eYcufLcfvVQoIqZdt5nUBit9Kn2nOkBidOIessiYLQ6lqiUca3/+9jnPfLtwAAv3ltM7YdaME7m+Pdk8yMN8wEDNWGtmDEdXBxzoTKbl13InJaHCJRxqHWIAZ5sBx0v15ze8hy0zy7chfOuW8xAGPGrZoVrMzWRIFSfeT86vq9cSMj/YHRRxb6ewHc3uA16Y6XUac9LAOL83HS6HIAwF/e325r4/7mDut4n3/offz0xY3WvrufN8xhJUzKhaF35LpANreHkR/wWTevGu08v3o3PtjaYFs24+HFW/Dn97dr30W8OOiWVH7A7yqyRtziCKJRRkswgitqRsaVAYD/W7YTQ8oKEy7roWhqs2fwON1zzoew/nAbKkoLLAF2EvATGo4ErWtvC0Xw4to9uMeMSbgxeVh/AMCH2+yJD8py8FFswKFfq88WkDaue6IpDjtMazMUiaK0MA95fsKRjrBlnZUUBGz32IEW+4Dn3ImV+PxJI6w2ONelag+7d1qAITon/PBlvLhmN3YfNp6ZQ61BvGO6TJLNGPcRobEthI+2HUQownGDMDXj/dOGFnz9b8uxVJvMuMlMXki04KFugSurN1HcykvGXXsogt2N7SgtiHe/qgw29exYa1qZ971bH3G4NWQlkbQGI3j0g+047o6XrHYBwH+ePwGr7rgwoUu1u3gSByKaSUSbiKiWiOa77Cciut/cv5qIpqWqS0T3EdFGs/yzRFSu7bvVLL+JiC7qZhsT0tgWAjMwoFhZDu43ATPb4gB7mzqwWwvwqg72tHvfsGYFJ3IrHWwJ4ieLNlgpd6MGFuFIMBz3cOkPq/73du2mbmoP4d3NB+LmJegdy6DifDx74xk4a3wFXliz2/IXR9gQxj2N7QldModbg5Z1okZVegBd/X2wNYim9jDKCgOWxTS41Bilq+wu3RJa4wigHemI4EhHGIvM76SxLWQbneb7yTZBY09jOz5z35s46e5Xcd4v3rIeOjWb2o1E8Yb+RbFZ0063kjOw7xSBQ60hVJQU4N4vnIAn/99pccf+cJsxq3jrfnvO+7tJJoopEXYGx5Vl0C8/YAmB/rupGM/Og63YsNvoQMZWFoMIqDMFPhgxguOlhXlobo+5lQaV5FuuJ8CYJKcnJ4wfUorPTDSEsT0UiZv13RGKxgnG41871WpHc0cYP31pI+rN2M8gzYJLtnS6j2CL6TkTJvqZcZxVOxvx4to9uEJL0pj31+XY09hum8uho78mVg3UEg3krvrDEvxc8/O7MePe1/H3j3agpDBeHNQzoD87bcGINRGvqT2EhavqbRmBalA2fnAJWoJh3PFPw+WlZo9/87zx+Nb549G/n33WfzpJKQ5E5AfwIIBZACYBuJKIJjmKzQIw3vw3D8DDHuq+CuB4Zp4C4BMAt5p1JgGYC2AygJkAHjKPk3ZUp2vFHCJRVxeR3iEDwL/97gMkS0T4zWubrVmvanLQwZYg3ty0D9PufhWPvL0Vyz89hHy/D6UFeegIReIsB5WfvqauEb/RshV0c/hwawhvb95vGwUB9gdugNlhjhnUD4daQ7EAcTCC5nZj9Livud3KgNHZsv+I1fG2uYiD+v4OtxhupdLCPOvBHznAiDlscgnYO32srR1h3Pz4Ctz42ArUHWrFiXe+gpsfi2V55Qd8tk57xr2v234T9XAnE4fh5e5B43/edAbu++IUlBUG0NQetgekHR1eZWm8W6qypADFBQFMrx4Yt089yAMcD7Dq1NxQHWirY+ar8r8X5fstoVj+6SHbqq0A8F9PrbIClsX5AZQWBCwrNhiOIs9PKCkIoLk9bAVrRw3oZxPvhpYOK841c/JQ/NeFE6yOs7k9HOdH73C4MtW5AVjJAH4iy3IYpP1OySZMRtgeOHau2qrcLZv2uid9NLeHEAozhpYV4u9fm2Hbp59XtT1RJtmSrQfx0OJarK93Pw8Qs/T19bue/vppOGFEf2vWuP7s7DzUarWtsTWEb/59Jb7wUGxCnhKvCUNKbX3NAdP9VzNmQMJrSRdeLIfpAGqZeSszBwE8AWCOo8wcAI+ywRIA5UQ0LFldZn6FmdW3tQTASO1YTzBzBzNvA1BrHiftHOkIo1++38hWSjLDc2mCtXfGDS5x3f6r1z7BOvNGKgj4EI0ypt39atzyCkX5fhTmGa6YtpDdtfKVPy3FnAfexeceeBdbtSwIXQi+94/Vrpke+5pio0DVYZYV5qGpLeS6OmX94TbbA6uo3XfE6qRaghFEo2zLxW9oMY6h3EqlhQHc98UpeOCqkyyXBmAPqAHx4nCkI2ylhaqHTB8l5gd8SZeoVmKYTBzGVhi/1UvfPgu/+/LJ1vaqimJcUTMKZUV5aGoP2QLhzvz+MhcBda7X5MYL3zzL9pmIEi4PoSY1OZMD1Dsy+uX7LSvh64+twKvmWllumT2FeX6jXWqhvQgjP+BHaWEAR9rDCEeiCPgoLtuq4UjQ+k4vO2kECgJ+K9vqocW1eHldLCgfMIPuceJgvjtih5nt5veR1eHp1loyVNBa4bxv1OddLjEHwBjUbdrbjJOrBuC0YwYlPI9x/+3DS+v2JCwTZWOZbMWSrQ34/EPvubQ7do+cPGYgJg8vwzZzQKe35S/vb7dc0G6z/5Xl4Oxj9jUbAlvm8TvsDl7EYQQAPZ2gztzmpYyXugDwVQAvduJ8IKJ5RLSMiJbt39+1NZGmjirH+rtm4sxxFcgzA356TnfdoVb824IPrHRCnXV3XoTJw8sSHvsDczmG3Y3tGPv9Ra5livONh649FLXW3HlE67hWOYKSqnNS1kiiDrPucExABvQzxaEoD+EoWyNCXUDqDrW5+ow37G5GqylaG3Y34bKH3rPFOVQQUwWkSwsDGFCcj0umDLf5QVUGk1XP8ZDrMQeVHaWT5/cl9ftuO2CM0CtLChK+ha660nAJHTu0DMcNjf/dSgvz0NQWds15V7j5dsuLEgsSYLhGnC6tVTsP47IH33e1UpUoOIP0AVMdivL8OO+4IbjuzGoAsSBowKXdhXk+9C/KwzMrd+H+1zdbqawlBQGs2HEIDy3egnCUbeIwoF8ePtp20EpIKDetHpUQsKfJHqwuLghYloM+wFDZZTvMjtHvIytjzusEsWA4ahtt651oOBK13DKJVnP92qPLALh/NzotHWF8xWVdLJ2KknxrdeMnl+3EXDPJYtuBFttzWFoYsHXo5f3y0dgawsGWoC3V9U0z+SPgI9dZ7PWH21AQ8FlZfwr13LpZ+unGizi4fbPOXzdRmZR1ieg2AGEAj3XifGDmR5i5hplrKiu7F60nIlumi3poH168BR9tP4jHtEXdFMUFAVsmhNMkVUHhZCtMBiOMwoAf7aFYQG9o/0JbB6e7MlQqZqUjrXRoWSEumTLM+rxWm1uhHlg1WlNm6d7m2ANVf7gdbcEIThjR33bcdfWNNvfG6rpGW4aUGrkdVJZDQWw0o8daTq1OPGoD7PMc6lxGgU63kpMb/ma4oAaVFMRlLKk4QfWgWLzALbhdUuDH4k37bBaL04/uJg6pRsFlRXnW0hI6G3Y3uYq7JQ4OyyEWczAs3R9cMgklBQH87KVNuPj+d1zfDFeY57fmRPzy1U/MmAOhtDDP5lYZoYlDWVEeGlqCeGbFLlv7VLDWmbRRUhAwLYcoKkoKcOa4Cvz8ihMt15mKx/mIcMDMgvK6qF4wErG7lcxO9KW1u7FcW/Yi1ZIdSmDyHfG/wjwfiIz7WAlI1aB+cUu7A8Ck4f0tMbpbm7twqCVoSzXP9/uw6JtnYePdMwEY4hqMRHHV75fge/9YbZWrb2zHiPIijBnUD/WHY8/iVnOgU3/Y2K/e3qewLIfC7LAc6gCM0j6PBFDvsUzSukR0DYBLAHyJY8MoL+dLO/laMEoFXxNlL11vjtr0h37X4fgRrxvHDYuNWkcOKEJhnh9toYiV8tcvP2C7OcuL8nDxlGH43InDMXqg0cE5XRkd4Qi+ff541/NVmZ2jupmUO0nPhtp1uBXtoSjOHF+Ba8+osravq29Cs6OTOqClOaqH9XBrEIda7Uti6x2wc/SjE/CRzS3gJg4BH8FLlvGgkvy4DmDe2WMBxCwHAK4pr/2L8hGOMp7WJhM6OzG3dFpdHCYNi7dIkomH2whaCZIzOUK1q0iLVyjBWFffFBcX85Eh0PrkRWU5OEed+rIizk5HWZ6q7fp38siXT8bQ/oWG5RCOoDDPh79dfyq+ePJIy3JQInSkI6yJg7eU8U17juDnr8QmpR1sMdyiN/xtBf7dXAurOEn8RqEyC1UmkfreBhUXYHj/ImxvaMGYQcY92hKM4F/fODNu+YzjhpUaGV6RKGqqYv7+tz7ZjwferLU+R5iRH/BZA4ly8/d3W/qlpCCA8n75Nmv5t28Yx6o73IYRA4qs71GhEgeyxXJYCmA8EVUTUT6MYPFCR5mFAK42s5ZmAGhk5t3J6hLRTAD/DeBSZm51HGsuERUQUTWMIPdH6GHytDzyLzz0PuY/vTouqwYAvnvhBNx28XEAgB9cPMl6aNUIaWhZIaaOKk94nu9eOAHb7p2NF791Fh65+mQU5vmxdX8L3jJ97kX5flvAsn9RHh68ahp+e+VJGG12sseabpGKEuPBvXzayLibCAA++v55ViA2ZjnY3QID+uVhx8E2BCNRFOX5bR1nazAStyaTPs9CuYcOHAniwJGgbUnsQk1sk8UC+uX7sVN7ONzcSs3t4ZTvTDbakm/7HasrinHl9NHY/tOLbYLrFBAA+P7sY802xdrryXLQgs3/+PppOG2s3UrSO9vXvnO2bd+NWtA9Feo4uhsrWaZPwG/MrdCt0HZz9VRnxzJA+32cYjbIvMdU2/drbqUZxwxCYZ7PdItGrNeQAsZ3rLtzDrUGY+Lg4RWtAPDaBntsY39zR9xcgrPGp/YaqEUiVbtVgkD/ojwcM7gEW/YfsQLuv7+6BtUVxfjclNjEsjGD+lnLn4y77UU0t4dxjDnY+N3bW23LWTitwfJ+ie/94gI/KkryrXkaRXl+vG8Gr+sPt2F4/yIrdqP4tKEVZYWBHktf1UkpDmbQ+GYALwPYAOBJZl5HRDcQ0Q1msUUAtsIIHv8ewI3J6pp1HgBQCuBVIvqYiBaYddYBeBLAegAvAbiJmXv8DeZ6h7FpbzOeWLrTVe2jHLMYhvYvxG/+fSoAWOmDP7/iRNfMFYVyMxw3rAyDSwstc/2ZlYYZX5Tnt40O9QdZ9dvDy4uw6ocX4p1bPotVP7wQt84+zjUDRg+OqRGk7u8/e0IlTh4zEFtM11dRnt9a08gt+ArAtoaSs7/WZyDrloMzWwcwUvFe/vbZKCkI2KwFN8vhcGtsclqyTB+/j6wVZb92VjX+9Y0zXcu5iUOV6XbS55+0hyK2vPWifDeLI9a2fvmBuKwofeQ+bnCpzbrQJx2mQt0H5R5TF1V2k+7u7AhHMbi0MM460I/pXCZF3Q+VpQUo75dnsyQLA34UBPxo6Qhje0OLNVhR6L9Vc3sYe5s651bSGVtZjBU7DtncSWeOq3DNILviZPt8F3XPq8mDsThcAGMrirFtfwua2kP4/Ekj4gZ2F08Zhue/caYtALzjYCuG9S9yjWU4BzFuv5dK8y4pzMPEoWWWh2Ly8DIcag3h/F++hf3NHRheXmQ9w6M163tspXsiTLrxNM+BmRcx8wRmPoaZ7zG3LWBm1aEzM99k7j+BmZclq2tuH8fMo5h5qvnvBm3fPWb5icz8InoBt2Uu3H5853R8ldd838ubQGS4L86dOBiAcUMDhvtoya3n4bbZx8WloOkjACKjs5l9fCx+4PfFrutscxLWeccORv+iPBTl+9G/KA9+H9kExe3Ybj7KWccPxeiB/azMiMJ8vzUTtzSBT3N1XaN1czvR3RO6BRLw+zB6YD/bQztpWCkmDi1FWVGeTRDcBPlwWxB3zZmMipICfPj986ztXz2jOq6sEpGRA9x9x4D77+rzEfIDPtss2Y5wFAO1Ds81IO14+J3C4/zeu7osvLKIBmgj0T9cXZNwXSflFnFaP8PKC+Pma+jWiB430inM8+PGzxwTd02FeT5s3NOMvU0dttE2EMuoGe/IuOnKst4Th5bho20Hcftza5Hv92HtnRfhD9fUuM4rOHN8he3zL644EUAszVRdV0lBHk4Y0R8twQjqDrW5DojOP24wSgvzbPv2NXegpCBgWVU6zmkV+v2hnn31G5YWBGyDhQlmhp+KUw4szsOEwaW489LJ+OdNZ1jlxiaYdJlucnqGtI7bKqC1P5mN71wwwbbNuZCX3gFdOX00RpQX4bRjBmHNjy7E2abJO7x/EYb2L8TXzh4bF5zU/dj5fh/8PsJ3LpiAm88dB8D+noKzxldi490zcaKL20p1xsP7F1rZMbpLwc33XV1RjC+fNsZ2LWrgo5uzZztmBh87rAz/c/kJcccbVh6zHAJ+HypK8nG76YJ7+5ZzccvMY6396gF1prm60R6KYs7UEVh2+/k20aqqiI2mlGCpbKpkI2z1GzhnxBYEfLblHtpDEWvEPmlYmaeAtHOQ4RQHNWo+d2LnkihUDEJv1/mThuA3c6e6lleprc7g+7D+RbY0Y8AuaG6DDL2uDhHZ3IdOi1kNFs4YV2FNogOSz4pOhN45zzhmEEoKDNeKev702IM+ye7P156Cy81BiRKSU6sH4uQxA3Dh5CG47KQRVhwwWXqoc1+/Aj8GlxbGrTmmL3MC2IX3yf93GmrvmWW5WUsKAraMx2O132XCkBKcMa4CPh/hmtOrbK6/sZW9Iw49H9U4SnCO+H7178Zo4z9mjMHv3tqC/7xgAn78wgZcNtWeVau7ffSMmNLCPKszSbbgm95BKYHy+QjHDjNuFGf+eiJfIxHhr9dNx4QhpfD7KG5WrlsAa2xFMQZri8YV5fkts1iPYVwyZRge/ep0nPWzN7DzYBsqivNxxriKuOM5UzaX3X6B7bPudlCdqtvIV01IS4Vuwbx9y7kAYi8qShYEB4xRt7OTLMzz27KVOswA7vPfOBOjBvSzpZeOrSzG1v0tCcXhpNHlWLnjMI4bZj9H/6I87ESbqzskESUFsZnnTh+226AGiKX8/fQLU3DVH5ZY98Pw8kKb9eEkmTi4zYWxu0Dd4xUVJfmYMXYQFm/ajyFlBWh0rAnmo8QvmJo0rAxXnjoan5lQiXCEQQTc/Nlx1n4lDvqg68RRsaw7/T5Q3/nEoaW2gcq4wSXYsLvJ9oxMrx6IhavqrfkxTpEvzg/g7suOR8BHuOS37+KcCZWoGtQPXzMTIBRKzKeOKofPR/CBrOywksIARg4osu73CUOMe6V/UR5e+c9z3L8QpL6304WIg4nzIfv8ScZoY2BxPtbdZaSlXX/W2Lh6+sPqDLyql88nmiwH2Dv70S4/emdeOqIH5+JHND4U59s7P/Ww9C/KQ2NbCEX5PkscdMtBzXYdW1GCnQeNLAq3F+e4BcXtbYm3ZNxu9OHlRWjS3EvOtpw1vgLvbD5g62CdojlqQPIH6PxJQ+K2FQR8aHVkZ+UHfDjeTPHV02kfv34GPtzWENdmNcj40qlj8MzXT4+zFH/35Rq8tn6vLUUzFaWFAStd0hm/SSgO5mmH9i/EHZdMsvL4B5caqdLXnDYGz67chamjHW5OzRJwWqgDXMRB/Y4FAV/cAEsJ5cDiAsw8fiiW3Hoefv3aJ3hiqX0V1kElBbbEh59dPgW3PG2kff7si1Os7/9/vjgl7vxKHAYW51tpwLpI6Zbpf888FiUFAczS3LZAbJChZ4h96dTROGdCpXV/OmMx/Qr8Vnxi+e3no6Qw4Lr8RmGeH8/eeLrV8evXlG8uyDhpeBmWbD2IYypLcM1pY3BFzai44+gkWgU43Yg4mHjJhnFDH005xUH50lWanBu6ZfD7a2qsv9XlpFrTvjP0L8pDSzCCE0eV48bPHGN1XIOK89HYFkJhnt8awemdngos/r+zx2JsZTGuP2ssfD7Cn75yCoaUFeKLC97HDz/nXFEl9bUA7pbD8PIiK/bw7I2nxwV5H/rSNHywpcFK7XXDGRz1QkHAF7emkd756i7Aof0LMcdhRapjAEan5Ta/YUR5Ea45vQqPvO19Df6SgoCVEhpvObjfH7Z3TmudpXI13jnneNw55/i4esqSPW5YGR79qn1hAjfLQf2ObpMPlVioZ2to/0Kb2+32i49DYZ4f79UewItrY7OT/+2UUZY4pJpHogRhevVA/P7qmjgLWR809C/Kw/dnHxd3DGXx6nNLiMg2cHG6lYq152OQy3L2Oic5BFj1E8oanDy8P5ZsPYjSwoDrb+Kkt8RBYg4mXQmSAfbRsFMc1DHHDErciakyXzur2jbKOf+4IbhkyjArbTYdqBt8xtiBuGhybNayGhESyJohXOySMXX6uAr88HOTrQf23GMHY9LwMqy/ayb+/ZTRnq7h7suOx+DSAmvEN230AJw4qhzP3Hi6VUZ3T00dVR73MJQW5uHCyUOTukDcOuZUuLnsdHFI9G4OHdUhJsr2ih0r8bU7YyH9CgI471gjyaHKMdBIZDnog4qJQ0tx7sRK61WlyVDfwXHDSuM6Zt1y+LWZpafKuA2uzpkw2DqW2/W2dETwHzPGWIL3/DfOxP/Ns6+BlGqy10WTh+LMcRX43kUTMXFoacI1tJLxpVPH4MszxuBrLp4B/Tpe/Fbs+0uWNZcK5WpS1uB1Z1bjF1ec6Dk9NVFCSLoRy8GkOIVLxAtOcbj7suNx8spdmOKYeayjApTOzqIo348HrprmVqXLqGDZQMfos6ZqAJZ/eggFeTG3Uj9bGmz6ZmN+eYbxICoGlxXaMjEA+2g0WSfvNinthW+eGZeh4xW3zl/vZFMt+W0cw7imRNleCrd0WkVZYR7aQzE3S+3eZjz79dNxzRlVcZ2l3tkOLi2wJknpV1pSEMCfrk2+PNlr3znHXMK9xawf31b9XJeZS3irjs4tZnDxlGE4pfo8DC6Nibvu1jxjnDEnZNTAIlSUFFjuI51Uk72G9i/E364/NW77X6+b7rmzLcr34+7LUo/Y9QmsxQky4bxw1vhKDCzOx3VnGmI0vLzICpp7oTvn7gxiOZhMrx6Ih740DXl+wg3nHJO6ggtOn+yI8iLcdO64pJ2KshwSrSWfTtTLXZzX+b0LJ+Kv103HtNEDrJnI/VKkwfYkqoNN1Rf7fYSpo8qtVEXAMNFP7uKKleq8Z2mpkG4D8yFliUdullsppeWQRBwcYhyOMnw+cv0d9OyYCycPsSbaddZyGje4BKcdM8iql6j6lJH9bSmt6loTvS9ZFwYgtsrqb+ZORU2Vkd301TOqseib7nNSvAiyG2eNr8QpVYnnG3WX7lgOA4vzseIHF3T5Pu0txHLQmH3CMMw+YVjqgg5uOvcYPPjmFk9T+Z3MPWUUFn5cjy9M8z5y6CpqDoAzWyXg91nBbJVJoS834XUVzXShhNLLAm3POayOdKBbgE5f+kvfPitubSudc48djJvPHYcxKTJKkrmVdJfUb+ZOxTFJJj3Z5pP4fNaossuhKvMrT1R94c32TjzmVvJ2eLesq8I8f6/M+E0HE4aU4JO9R9IaC/TKf10wwfV96z2FiEMa+N5Fx+J7Fx2buqALYwYV4735n03zFbmjsm0GJllm+iunV6G6oh9OP6YCtz1rvEK0N6wahcpfB+JnYPc0aiFFXQydncCxLiu66gwpK8R3L5qY8lzJLIeBWp7+7BOGJYwrAHZXT56ftHWDOh+QBwA21cFr36c6+WRLquuoOFGq63vlP8+OW+olG/jztdPxg+fWJl0Foaf4xnnu66f1FCIOOYQKNiezBPw+wmePHWJzE3QluNsV1t55EXwELPy4x9dZdMVNHBItAd5d9JjDgv84GSMHFFlvG9QzrVItN62Lg9/nw+DSQvzoc5NwgZZw0Bk6K8idtSrv/cIJOHtCZdLl7gHjJTd6+me2MLy8CP/7lVMyfRm9gsQccojPmMt66CPTRPSWIOiUFATQL793FhVzIxiJF8+eEgfdchhSZg/G6vM6Uv0Oeiqr+vsrZ1R7mnnuhpqwmcyVpaNcqbfO8mY5V5QU4MszxmTk/hI6h1gOOcRtFx+H686sTrpKajbgdXG5dKMsBz0g7O+hTkxfwdTpNupMOiYRWTOM0yFkn5k4GI9dfypmOFaXTXb+7T+9uNvnFbIPEYccIs8f/2apbMQ5I7q36FW3km1hQvs5hpd3bpITEQHMSWMTncFtaRQh9xC3kpCUrgY2u0OmxEEtnaynjHY1lTIV+oJ4AZ/9MeysS0hdYU8JmZCbiOUgJGTZ7ed7mhWcbjLl9lKWg76uVI+5lQK6ONjPkWyhRjfUJaYKXgtCZxDLQUhIRUlBypm+PUGy2cM9ye++fDIuPmGYbeJWzwWkYwLkdCsleg9FItRs5nS5lQQBEMtBECxOHjMQJ48ZaFshtKcmO+kC6Hyndaczeczi4lYS0okMNQTBgd7J9tRgXHcrdTfGomIlvfHSeSF3kLtJyErem/9Za9Jeb6MPwHssIB3w4apTR+PSE4en7RydeYGQIKTC07iIiGYS0SYiqiWi+S77iYjuN/evJqJpqeoS0RVEtI6IokRUo22vIqI2IvrY/Legu40Ujj5GlBdlLO1Wd+v0VECaiPCTz59gm0/ws8un4Cefj3/9qld6aylnITdIaTkQkR/AgwAuAFAHYCkRLWTm9VqxWQDGm/9OBfAwgFNT1F0L4AsAfudy2i3MPLXLrRKEbmB3K/WeH//fTom9AeyOSyZZ6/17JVMpwELfxItbaTqAWmbeCgBE9ASAOQB0cZgD4FE2FuRZQkTlRDQMQFWiusy8wdyWrrYIQlqwuZUydH9+9czqTtfp7dVzhb6NF7fSCAD6S1/rzG1eynip60Y1Ea0koreIKPXrqwQhjeiCcDRlAMlAS0gnXiwHtzvOGSlMVMZLXSe7AYxm5gYiOhnAc0Q0mZmbbCckmgdgHgCMHu3tFZWC4IWjTRwKAr4uv+ZWEBLhRRzqAIzSPo8E4FxTOVGZfA91bTBzB4AO8+/lRLQFwAQAyxzlHgHwCADU1NRkJq1F6JPoM40z5VbqDB/ddr7n9ykIgle8uJWWAhhPRNVElA9gLoCFjjILAVxtZi3NANDIzLs91rVBRJVmIBtENBZGkHtrp1olCN3A1wvzHNJJ/6K8rF9pVzj6SGk5MHOYiG4G8DIAP4A/MvM6IrrB3L8AwCIAswHUAmgFcG2yugBARJ8H8FsAlQBeIKKPmfkiAGcDuIuIwgAiAG5g5oPpbLQgeOVosBwEoSfwNAmOmRfBEAB92wLtbwZwk9e65vZnATzrsv1pAE97uS5B6GmOhpiDIPQER4HRLAiZQ8RByFVEHAQhCeJWEnIVEQdBSIJYDkKuIuIgCEkQcRByFREHQXBBaUJPLbwnCNmOiIMguKBiDWI5CLmKiIMguKDEoafe5yAI2Y6IgyC4IW4lIccRcRAEF6yYgzwhQo4it74guGC5lcRyEHIUEQdBcEEC0kKuI+IgCC4og0EC0kKuIuIgCC5YloO4lYQcRcRBEFwgKyAt4iDkJiIOguCCBKSFXEfEQRBc8InlIOQ4Ig6C4AJZ2UoZvhBByBBy6wuCC8pgELeSkKuIOAiCCwSZ5yDkNiIOguCCWA5CruNJHIhoJhFtIqJaIprvsp+I6H5z/2oimpaqLhFdQUTriChKRDWO491qlt9ERBd1p4GC0BVIZkgLOU5KcSAiP4AHAcwCMAnAlUQ0yVFsFoDx5r95AB72UHctgC8AeNtxvkkA5gKYDGAmgIfM4whCr+EznwwRByFX8WI5TAdQy8xbmTkI4AkAcxxl5gB4lA2WACgnomHJ6jLzBmbe5HK+OQCeYOYOZt4GoNY8jiD0GirmIG4lIVfxIg4jAOzUPteZ27yU8VK3K+cThB4lFnPI7HUIQqbwIg5ujwd7LOOlblfOByKaR0TLiGjZ/v37UxxSEDqHijmkulkFoa/iRRzqAIzSPo8EUO+xjJe6XTkfmPkRZq5h5prKysoUhxSEzqG8ScwiD0Ju4kUclgIYT0TVRJQPI1i80FFmIYCrzaylGQAamXm3x7pOFgKYS0QFRFQNI8j9USfaJAjdRsUaRBuEXCWQqgAzh4noZgAvA/AD+CMzryOiG8z9CwAsAjAbRvC4FcC1yeoCABF9HsBvAVQCeIGIPmbmi8xjPwlgPYAwgJuYOZLWVgtCCorzJUFOyG2oL5jNNTU1vGzZskxfhtCH2HW4DU8t24lvnTfeij8IQl+DiJYzc43bvpSWgyDkIiPKi/Dt8ydk+jIEIWPI8hmCIAhCHCIOgiAIQhwiDoIgCEIcIg6CIAhCHCIOgiAIQhwiDoIgCEIcIg6CIAhCHCIOgiAIQhx9YoY0Ee0H8Gk3DlEB4ECaLudoQdqcG0ibc4OutnkMM7uuXNonxKG7ENGyRFPI+yrS5txA2pwb9ESbxa0kCIIgxCHiIAiCIMQh4mDwSKYvIANIm3MDaXNukPY2S8xBEARBiEMsB0EQBCGOnBYHIppJRJuIqJaI5mf6etIFEf2RiPYR0Vpt20AiepWINpv/D9D23Wp+B5uI6KLMXHX3IKJRRPQmEW0gonVE9C1ze59tNxEVEtFHRLTKbPOd5vY+22YAICI/Ea0koufNz326vQBARNuJaA0RfUxEy8xtPdtuZs7JfzBeW7oFwFgA+QBWAZiU6etKU9vOBjANwFpt288AzDf/ng/gf8y/J5ltLwBQbX4n/ky3oQttHgZgmvl3KYBPzLb12XYDIAAl5t95AD4EMKMvt9lsx3cAPA7gefNzn26v2ZbtACoc23q03blsOUwHUMvMW5k5COAJAHMyfE1pgZnfBnDQsXkOgL+Yf/8FwGXa9ieYuYOZt8F4D/j03rjOdMLMu5l5hfl3M4ANAEagD7ebDY6YH/PMf4w+3GYiGgngYgB/0Db32famoEfbncviMALATu1znbmtrzKEmXcDRkcKYLC5vc99D0RUBeAkGCPpPt1u08XyMYB9AF5l5r7e5l8DuAVAVNvWl9urYACvENFyIppnbuvRdufyO6Td3hqfi6lbfep7IKISAE8D+DYzNxG5Nc8o6rLtqGs3M0cATCWicgDPEtHxSYof1W0moksA7GPm5UT0GS9VXLYdNe11cAYz1xPRYACvEtHGJGXT0u5cthzqAIzSPo8EUJ+ha+kN9hLRMAAw/99nbu8z3wMR5cEQhseY+Rlzc59vNwAw82EAiwHMRN9t8xkALiWi7TDcwJ8lor+h77bXgpnrzf/3AXgWhpuoR9udy+KwFMB4IqomonwAcwEszPA19SQLAVxj/n0NgH9q2+cSUQERVQMYD+CjDFxftyDDRPhfABuY+Zfarj7bbiKqNC0GEFERgPMBbEQfbTMz38rMI5m5Csbz+gYz/wf6aHsVRFRMRKXqbwAXAliLnm53pqPwGc4AmA0jq2ULgNsyfT1pbNffAewGEIIxirgOwCAArwPYbP4/UCt/m/kdbAIwK9PX38U2nwnDdF4N4GPz3+y+3G4AUwCsNNu8FsAd5vY+22atHZ9BLFupT7cXRkblKvPfOtVX9XS7ZYa0IAiCEEcuu5UEQRCEBIg4CIIgCHGIOAiCIAhxiDgIgiAIcYg4CIIgCHGIOAiCIAhxiDgIgiAIcYg4CIIgCHH8f1lNdqd5SmoIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X,y = next(iter(data_module.val_dataloader()))\n",
    "pred = model(X)\n",
    "\n",
    "plt.plot((5e-1*pred[0]).softmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/datasets/moving_dataset_small.hdf5\"\n",
    "sound_dir = \"./data/reference_data/reference_sounds/\"\n",
    "data_module = MovingImpulseResponseDataModule(data_path,sound_dir,batch_size=2)\n",
    "\n",
    "model = cnn_model()\n",
    "data_module.setup()\n",
    "X,y = next(iter(data_module.train_dataloader()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doppler augmentation. \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize=(16,6))\n",
    "#plt.plot(X[0,0,200:500],'.')\n",
    "\n",
    "class doppler_aug(object):\n",
    "\n",
    "    def __init__(self, max_rel_v = 3):\n",
    "        self.max_rel_v = max_rel_v\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        X,y = sample\n",
    "        factor = (2*self.max_rel_v*torch.rand(1) + 343 - self.max_rel_v)/343\n",
    "\n",
    "        freqs = X.shape[-1]\n",
    "        if factor < 1:\n",
    "            x = torch.arange(freqs)*factor\n",
    "            w_lower = 1 - (x - x.int())\n",
    "            X[:,0::2] = X[:,0::2,x.int()]*w_lower + (1 - w_lower)*X[:,0::2,x.int()+1]\n",
    "        else:\n",
    "            x = torch.arange(freqs)*factor\n",
    "            x = x[x < freqs - 1] # make sure we don't query freq values outside of input vector\n",
    "            w_lower = 1 - (x - x.int())\n",
    "            \n",
    "            X[:,0::2,:x.shape[0]] = X[:,0::2,x.int()]*w_lower + (1 - w_lower)*X[:,0::2,x.int()+1]\n",
    "            X[:,0::2,x.shape[0]:] = 0\n",
    "\n",
    "        return X,y\n",
    "\n",
    "class noise_aug(object):\n",
    "\n",
    "    def __init__(self, noise_ratio = 0.01):\n",
    "        self.noise_ratio = noise_ratio\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        X,y = sample\n",
    "        X += self.noise_ratio*X.std(dim=(1,2),keepdim=True)*torch.randn(X.shape)\n",
    "        return X,y\n",
    "\n",
    "\n",
    "#plt.plot(X[0,0,2000:2500],'.')\n",
    "\n",
    "\n",
    "\n",
    "#(torch.arange(2500)*factor).int()\n",
    "#(torch.arange(2500)*factor).int() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "# wandb_logger = WandbLogger(log_model=\"all\")\n",
    "# trainer = L.Trainer(\n",
    "#     max_epochs=50,\n",
    "#     accelerator=\"cuda\",\n",
    "#     devices=1,\n",
    "#     logger=wandb_logger,\n",
    "# )\n",
    "# trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 51, 10, 1600)\n",
      "<KeysViewHDF5 ['fs', 'n_mics', 'n_rooms', 'reflection_coeff', 'rir_len', 'room_max_size', 'room_min_size', 'scatter_coeff', 'sound_source_locations', 'sound_source_max_move', 'speed_of_sound', 'target_path']>\n",
      "torch.Size([30, 51, 10, 1600])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_path = \"./data/datasets/moving_dataset_medium.hdf5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    print(f[\"input\"].shape)\n",
    "    print(f.attrs.keys())\n",
    "    X = f[\"input\"]\n",
    "    print(torch.tensor(X[:30]).shape)\n",
    "    print(torch.tensor(X[:30]).std(dim=(1,2,3)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([680])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_module.train_dataloader()))\n",
    "X,y = batch\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "from scipy.io import wavfile\n",
    "sample_length: int = 10000 #number of samples\n",
    "max_freq: float = 4000.0 # Hz\n",
    "batch_size : int = 1\n",
    "n_mics_per_batch = 17\n",
    "max_shift : float = 500 #samples\n",
    "n_shift_bins : int = 500\n",
    "validation_percentage = 0.05\n",
    "\n",
    "# remove\n",
    "dataset_metadata = data_module.h5file.attrs\n",
    "dataset = data_module.dataset\n",
    "sound_files = glob.glob(sound_dir + \"*.wav\")\n",
    "\n",
    "#const\n",
    "rir_len = dataset_metadata[\"rir_len\"]\n",
    "batch_size = X.shape[0]\n",
    "n_sound_positions = X.shape[2]\n",
    "sim_sample_length = sample_length + rir_len # length used when simmulating sound, needs to be longer than the final sound to have echo in the entire sample\n",
    "\n",
    "\n",
    "# randomly select audio pieces\n",
    "\n",
    "signals = torch.zeros(batch_size,sim_sample_length)\n",
    "for batch_i in range(batch_size):\n",
    "    sound_file = sound_files[torch.randint(len(sound_files),(1,))]\n",
    "    fs, signal = wavfile.read(sound_file)\n",
    "    if fs != dataset_metadata[\"fs\"]:\n",
    "        raise Exception(\"Please use .wav with the same sampling frequency as the simmulated impulse responses sampling frequency (probably 16 kHz\")\n",
    "    start = torch.randint(len(signal) - sim_sample_length, (1,))\n",
    "    signals[batch_i,:] = torch.tensor(signal[start : start + sim_sample_length])\n",
    "piece_length = signals.shape[1] // n_sound_positions\n",
    "signals = signals[:,:piece_length*n_sound_positions].reshape(batch_size, n_sound_positions, piece_length) # splitting the sound into the different speaker positions\n",
    "#signals = torch.concatenate([signals, torch.zeros(signals.shape[0], signals.shape[1], rir_len)],dim=2)\n",
    "\n",
    "signals = torch.fft.irfft(torch.fft.rfft(X, signals.shape[2] + rir_len) * torch.fft.rfft(signals, signals.shape[2] + rir_len).unsqueeze(1))\n",
    "\n",
    "fin_signal = torch.zeros(batch_size, n_mics_per_batch, signals.shape[3] + piece_length*(n_sound_positions-1))\n",
    "for i in range(n_sound_positions):\n",
    "    fin_signal[:,:,i*piece_length:piece_length*i+signals.shape[3]] = signals[:,:,i]\n",
    "\n",
    "fin_signal = fin_signal[:,:,-sample_length:]\n",
    "max_freq_component = int(max_freq*sample_length/dataset_metadata[\"fs\"])\n",
    "\n",
    "fin_signal = torch.fft.rfft(fin_signal)[:,:,:max_freq_component].unsqueeze(2)\n",
    "fin_signal = torch.concatenate([torch.concatenate([fin_signal, fin_signal.roll(i + 1, 1)], dim=2) for i in range((n_mics_per_batch-1) // 2)],dim=1)  # organize sounds pairwise, \n",
    "# NOTE: if n_mics_per_batch is not odd, then we will compute all pairs of microphones except one\n",
    "fin_signal = fin_signal.view(batch_size * fin_signal.shape[1],2,fin_signal.shape[3])\n",
    "fin_signal = torch.concatenate([fin_signal.real, fin_signal.imag], dim=1)\n",
    "\n",
    "y = torch.concatenate([y - y.roll(i + 1, 1) for i in range((n_mics_per_batch-1) // 2)], dim=1).view(-1) # compute pairwise distance-difference\n",
    "y *= dataset_metadata[\"fs\"]/dataset_metadata[\"speed_of_sound\"] # rescale distance-difference to sample_difference\n",
    "\n",
    "bin_edges = torch.linspace(-max_shift,max_shift,n_shift_bins+1)\n",
    "bin_edges[0] = -float(\"inf\")\n",
    "bin_edges[-1] = float(\"inf\")\n",
    "y = (y.unsqueeze(1) < bin_edges).to(torch.long).argmax(dim=1) - 1  # Bins the values in y, since argmax finds first occurence where condition is met.\n",
    "\n",
    "\n",
    "\n",
    "#torch.fft.irfft(torch.fft.rfft().unsqueeze(1) * torch.fft.rfft(X, signals.shape[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_metadata[\"speed_of_sound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_simulated_data(X, y):\n",
    "            \"\"\"\n",
    "            transform a tensor of impulse responses in different rooms into pairwise TimeEstimation-problems. Note (X and y should be on GPU)\n",
    "\n",
    "            \"\"\"\n",
    "            # pull a random sound\n",
    "            sound_paths = glob(os.path.join(reference_sound_folder, \"*.wav\"))\n",
    "            # simulate longer sound and then cut to the relevant piece\n",
    "            signals = np.zeros(\n",
    "                (X.shape[0], config[\"sample_length\"] + config[\"rir_len\"] - 1)\n",
    "            )\n",
    "            for i in range(X.shape[0]):\n",
    "                sound_path = sound_paths[np.random.randint(len(sound_paths))]\n",
    "                fs, signal = wavfile.read(sound_path)\n",
    "                start = np.random.randint(\n",
    "                    0, len(signal) - config[\"sample_length\"] - config[\"rir_len\"] - 1\n",
    "                )\n",
    "                signals[i, :] = signal[\n",
    "                    start : start + config[\"sample_length\"] + config[\"rir_len\"] - 1\n",
    "                ]\n",
    "            # signals = torch.tensor(signals).to(torch.float32).to(device).unsqueeze(1)\n",
    "            signals = torch.tensor(signals).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "            q = torch.fft.irfft(\n",
    "                torch.fft.rfft(signals) * torch.fft.rfft(X, signals.shape[2])\n",
    "            )[\n",
    "                :, :, : config[\"sample_length\"]\n",
    "            ]  # compute the heard sound, and cut it to the right length\n",
    "            q = torch.fft.rfft(q)[\n",
    "                :, :, : config[\"max_freq\"]\n",
    "            ]  # cut frequencies which are too high\n",
    "            q = q.unsqueeze(2)\n",
    "            q = torch.concatenate(\n",
    "                [\n",
    "                    torch.concatenate([q, q.roll(i + 1, 1)], dim=2)\n",
    "                    for i in range(config[\"mics_per_batch\"] // 2)\n",
    "                ],\n",
    "                dim=1,\n",
    "            )  # organize sounds pairwise\n",
    "            q = q.view(\n",
    "                X.shape[0]\n",
    "                * (config[\"mics_per_batch\"] * (config[\"mics_per_batch\"] - 1))\n",
    "                // 2,\n",
    "                2,\n",
    "                -1,\n",
    "            )  # reshape so that each example is a row\n",
    "            X = torch.concatenate([q.real, q.imag], dim=1)\n",
    "            X /= (\n",
    "                X.std(dim=2).mean(dim=1).unsqueeze(1).unsqueeze(2) + 1e-5\n",
    "            )  # avoid dividing by 0\n",
    "            y = (\n",
    "                torch.concatenate(\n",
    "                    [\n",
    "                        y - y.roll(i + 1, 1)\n",
    "                        for i in range(config[\"mics_per_batch\"] // 2)\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                ).view(-1)\n",
    "                * fs\n",
    "                / 343\n",
    "            )  # compute gt for all pairs\n",
    "            y = y_to_class_gt(y, config[\"guess_grid_size\"], config[\"max_shift\"]).to(\n",
    "                torch.long\n",
    "            )\n",
    "\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"input\": shape (10, 51, 10, 1600), type \"<f4\">"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with h5py.File(\"./test.hdf5\",\"w\") as f:\n",
    "    f.create_dataset(\"metadata\",())\n",
    "    z = f[\"metadata\"]\n",
    "    #metadata = z.attrs\n",
    "    f.attrs[\"a\"] = 43\n",
    "    #metadata.create(\"a\",123)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f226e654220>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "with h5py.File(\"./data/datasets/example_moving.hdf5\",\"r\") as f:\n",
    "    X = f[\"input\"]\n",
    "    #torch.utils.data.IterableDataset(X)\n",
    "    print(DataLoader(X))\n",
    "    torch.utils.data.Subset(X,torch.arange(5))\n",
    "    #metadata = z.attrs\n",
    "    #for i in f.attrs:\n",
    "    #    print(f'{i} : {f.attrs[i]}')\n",
    "    #print(f.attrs[\"a\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 1, 'y': 2}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    print(locals())\n",
    "    print(vars()['x'])\n",
    "\n",
    "f(1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
